data_3035$spachar = ifelse(data_3035$population_1000 < quantile(data_3035$population_1000, 0.5) & ((data_3035$road_class_2_100 > 0 | data_3035$road_class_1_100 > 0) | data_3035$road_class_3_100 > quantile(data_3035$road_class_3_100, 0.5)), 2, data_3035$spachar)
#spatial character: group "far from road"
data_3035$spachar = ifelse((data_3035$spachar == 1 | data_3035$spachar == 2), data_3035$spachar, 3)
#now to spatial points dataframe
data_sp <- as(data_3035, "Spatial")
## == Kriging - variogram setting == ##
#define x & y variables to coordinates
data_xy <- data.frame(x = data_sp$coords.x1, y = data_sp$coords.x2)
coordinates(data_xy) = ~x+y
#variogram
#perform autofit variogram, based on dependent variable 'Lopend_gemiddelde'
variogram_auto_lin = autofitVariogram(Lopend_gemiddelde ~ 1, data_sp)
plot(variogram_auto_lin)
autofit_params_lin <- variogram_auto_lin$var_model
#examine suggested variogram paramater settings via print function
print(autofit_params_lin)
#manually insert variogram settings, based on autofit
m <- vgm(psill = 80.16775, "Ste", range = 98.67688)
## == models evaluations ==##
# leave-one-out cross validation - exclusion of predictors (i.e. ordinary kriging):
krige_ok <- krige.cv(Lopend_gemiddelde ~ 1, data_sp, m)
krige_ok$observed
#convert to dataframes - useful for evaluation purposes
data_df <- as.data.frame(data_sp)
krige <- as.data.frame(krige_ok)
#merge the kriging output with the initial dataframe - again, useful for evaluation purposes
data_merge <- merge(krige,data_df, by = c("coords.x1", "coords.x2"))
#narrow data
data_filtered = data_merge[, c("Lopend_gemiddelde", "observed", "var1.pred", "residual", "zscore", "spachar", "coords.x1", "coords.x2")]
## == overall evaluation == ##
#define R2
#R SQUARED error metric -- Coefficient of Determination
RSQUARE = function(y_actual,y_predict){
cor(y_actual,y_predict)^2}
#=================
#overall RMSE
RMSE_model = rmse(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("RMSE TOTAL: ", RMSE_model))
#overall R2
R2_model = RSQUARE(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("R2 TOTAL: ",R2_model))
#overall MAE
MAE_model = mae(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("MAE TOTAL: ", MAE_model))
Filtered_urban <- data_filtered[data_filtered$spachar == 1, ]
Filtered_lowpop <- data_filtered[data_filtered$spachar == 2, ]
Filtered_ffr <- data_filtered[data_filtered$spachar == 3, ]
#model evaluations
#define R2
#R SQUARED error metric -- Coefficient of Determination
RSQUARE = function(y_actual,y_predict){
cor(y_actual,y_predict)^2}
#URBAN
MAE_urb = mae(Filtered_urban$observed, Filtered_urban$var1.pred)
print(paste0("MAE URBAN: ", MAE_urb))
print(MAE_urb)
summary(MAE_urb)
R2_model_urb = RSQUARE(Filtered_urban$observed,Filtered_urban$var1.pred)
print(paste0("R2 URBAN: ",R2_model_urb))
summary(R2_model_urb)
RMSE_model_urb = rmse(Filtered_urban$observed, Filtered_urban$var1.pred)
print(paste0("RMSE URBAN: ", RMSE_model_urb))
summary(RMSE_model_urb)
#LOW POP
MAE_lowpop = mae(Filtered_lowpop$observed, Filtered_lowpop$var1.pred)
print(paste0("MAE LOWPOP: ", MAE_lowpop))
summary(MAE_lowpop)
R2_model_lowpop = RSQUARE(Filtered_lowpop$observed,Filtered_lowpop$var1.pred)
print(paste0("R2 LOWPOP: ",R2_model_lowpop))
summary(R2_model_lowpop)
RMSE_model_lowpop = rmse(Filtered_lowpop$observed, Filtered_lowpop$var1.pred)
print(paste0("RMSE LOWPOP: ", RMSE_model_lowpop))
summary(RMSE_model_lowpop)
#FFR
MAE_ffr = mae(Filtered_ffr$observed, Filtered_ffr$var1.pred)
print(paste0("MAE FFR: ", MAE_ffr))
summary(MAE_ffr)
R2_model_ffr = RSQUARE(Filtered_ffr$observed,Filtered_ffr$var1.pred)
print(paste0("R2 FFR: ",R2_model_ffr))
summary(R2_model_ffr)
RMSE_model_ffr = rmse(Filtered_ffr$observed, Filtered_ffr$var1.pred)
print(paste0("RMSE FFR: ", RMSE_model_ffr))
summary(RMSE_model_ffr)
## == Necessary packages == ##
# We will need some packages for (spatial) data processing
library(tidyverse) # wrangling tabular data and plotting
library(sf) # processing spatial vector data - the easy way
library(sp) # processing spatial vector data - the way gstat needs it
library(raster) # processing spatial raster data. !!!overwrites dplyr::select!!!
library(rgdal) #import shapefiles
library(rgeos) #contains gCentroid
library(tidyr) #geometry to apart long/lat
library(dismo) #for kfold
library(lme4) #for mixed models (random effects)
library(stats) #quantile
library(nlme) #mixed-effect model
library(Metrics)
library('parallel')
# Packages for geostatistics
library(gstat)   # The most popular R-Package for Kriging
library(automap) # Automatize some (or all) parts of the gstat-workflow
# Finally, some packages to make pretty plots
library(patchwork)
library(viridis)
library(tmap)
library(graphics) #for text
## == DEFINE COORDINATE SYSTEMS == ##
#CRS with metric system is preferred (=3035).
crs <- CRS("+proj=longlat +datum=WGS84") # crs
## == import geodata == ##
data <- read.csv('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/LocalModelData/ModellingDataset-Local.csv', sep=';')
#replace NA with 0
data[is.na(data)] <- 0
#convert to spatial points dataframe (gstat relies on sp package more than sf)
#first convert to sf
#to sf
data_sf = st_as_sf(data, coords = c("Longitude", "Latitude"), crs = 4326)
#change to planar crs
data_3035 <- st_transform(data_sf,crs=3035)
## == create column relating to spatial characterization (e.g. distance to road/population) == ##
#examine basic data statistics of variables that will be used for quantile filtering!
quantile(data_3035$road_class_3_100)
quantile(data_3035$population_1000)
#spatial character: group "urban"
data_3035$spachar = ifelse(data_3035$population_1000 > quantile(data_3035$population_1000, 0.5) & ((data_3035$road_class_2_100 > 0 | data_3035$road_class_1_100 > 0) | data_3035$road_class_3_100 > quantile(data_3035$road_class_3_100, 0.5)), 1, 0)
#spatial character: group "low population"
data_3035$spachar = ifelse(data_3035$population_1000 < quantile(data_3035$population_1000, 0.5) & ((data_3035$road_class_2_100 > 0 | data_3035$road_class_1_100 > 0) | data_3035$road_class_3_100 > quantile(data_3035$road_class_3_100, 0.5)), 2, data_3035$spachar)
#spatial character: group "far from road"
data_3035$spachar = ifelse((data_3035$spachar == 1 | data_3035$spachar == 2), data_3035$spachar, 3)
#now to spatial points dataframe
data_sp <- as(data_3035, "Spatial")
## == Kriging - variogram setting == ##
#define x & y variables to coordinates
data_xy <- data.frame(x = data_sp$coords.x1, y = data_sp$coords.x2)
coordinates(data_xy) = ~x+y
#variogram
#perform autofit variogram, based on dependent variable 'Lopend_gemiddelde'
variogram_auto_lin = autofitVariogram(Lopend_gemiddelde ~ 1, data_sp)
plot(variogram_auto_lin)
autofit_params_lin <- variogram_auto_lin$var_model
#examine suggested variogram paramater settings via print function
print(autofit_params_lin)
#manually insert variogram settings, based on autofit
m <- vgm(psill = 80.16775, "Ste", range = 98.67688)
## == models evaluations ==##
# leave-one-out cross validation - exclusion of predictors (i.e. ordinary kriging):
krige_ok <- krige.cv(Lopend_gemiddelde ~ 1, data_sp, m)
krige_ok$observed
#convert to dataframes - useful for evaluation purposes
data_df <- as.data.frame(data_sp)
krige <- as.data.frame(krige_ok)
#merge the kriging output with the initial dataframe - again, useful for evaluation purposes
data_merge <- merge(krige,data_df, by = c("coords.x1", "coords.x2"))
#narrow data
data_filtered = data_merge[, c("Lopend_gemiddelde", "observed", "var1.pred", "residual", "zscore", "spachar", "coords.x1", "coords.x2")]
## == overall evaluation == ##
#define R2
#R SQUARED error metric -- Coefficient of Determination
RSQUARE = function(y_actual,y_predict){
cor(y_actual,y_predict)^2}
#=================
#overall RMSE
RMSE_model = rmse(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("RMSE TOTAL: ", RMSE_model))
#overall R2
R2_model = RSQUARE(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("R2 TOTAL: ",R2_model))
#overall MAE
MAE_model = mae(data_filtered$Lopend_gemiddelde, data_filtered$var1.pred)
print(paste0("MAE TOTAL: ", MAE_model))
Filtered_urban <- data_filtered[data_filtered$spachar == 1, ]
Filtered_lowpop <- data_filtered[data_filtered$spachar == 2, ]
Filtered_ffr <- data_filtered[data_filtered$spachar == 3, ]
#model evaluations
#define R2
#R SQUARED error metric -- Coefficient of Determination
RSQUARE = function(y_actual,y_predict){
cor(y_actual,y_predict)^2}
#URBAN
MAE_urb = mae(Filtered_urban$observed, Filtered_urban$var1.pred)
print(paste0("MAE URBAN: ", MAE_urb))
print(MAE_urb)
summary(MAE_urb)
R2_model_urb = RSQUARE(Filtered_urban$observed,Filtered_urban$var1.pred)
print(paste0("R2 URBAN: ",R2_model_urb))
summary(R2_model_urb)
RMSE_model_urb = rmse(Filtered_urban$observed, Filtered_urban$var1.pred)
print(paste0("RMSE URBAN: ", RMSE_model_urb))
summary(RMSE_model_urb)
#LOW POP
MAE_lowpop = mae(Filtered_lowpop$observed, Filtered_lowpop$var1.pred)
print(paste0("MAE LOWPOP: ", MAE_lowpop))
summary(MAE_lowpop)
R2_model_lowpop = RSQUARE(Filtered_lowpop$observed,Filtered_lowpop$var1.pred)
print(paste0("R2 LOWPOP: ",R2_model_lowpop))
summary(R2_model_lowpop)
RMSE_model_lowpop = rmse(Filtered_lowpop$observed, Filtered_lowpop$var1.pred)
print(paste0("RMSE LOWPOP: ", RMSE_model_lowpop))
summary(RMSE_model_lowpop)
#FFR
MAE_ffr = mae(Filtered_ffr$observed, Filtered_ffr$var1.pred)
print(paste0("MAE FFR: ", MAE_ffr))
summary(MAE_ffr)
R2_model_ffr = RSQUARE(Filtered_ffr$observed,Filtered_ffr$var1.pred)
print(paste0("R2 FFR: ",R2_model_ffr))
summary(R2_model_ffr)
RMSE_model_ffr = rmse(Filtered_ffr$observed, Filtered_ffr$var1.pred)
print(paste0("RMSE FFR: ", RMSE_model_ffr))
summary(RMSE_model_ffr)
library(rgdal)
library(base)
library(dplyr)
library(purrr)
library(sf)
library(raster)
#global
global = readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/Grid100/Amsterdam_NO2PredictionPerModel.gpkg')
global_df <- as.data.frame(global)
colnames(global_df)
global_RF <- global_df$predicted_NO2_RF
global_xgboost <- global_df$predicted_NO2_XGBoost
global_lightgbm <- global_df$predicted_NO2_LightGBM
global_lasso <- global_df$predicted_NO2_LASSO
global_ridge <- global_df$predicted_NO2_RIDGE
global_models <- list(global_RF, global_xgboost, global_lightgbm, global_lasso, global_ridge)
for(model in global_models){
print(summary(model))
}
#local
linear = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_Linear.gpkg")
linear_separated = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_Linear_SeparatingSpatialGroups_1.gpkg")
linear_separated = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_Linear_SeparatingSpatialGroups.gpkg")
MEM = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_MEM.gpkg")
UK = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_UK_formula.gpkg")
UK_separated = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_UK_SeparatingSpatialGroups.gpkg")
OK = readOGR("C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/LocalModels/predictedNO2_OK.gpkg")
#make spatial - obtain the geometry for each sample
grid100_sf <- st_as_sf(linear)
geo <- grid100_sf[,c("key", "geometry")]
#to dataframe - for every local dataset
linear_df <- as.data.frame(linear)
linear_separated_df <- as.data.frame(linear_separated)
MEM_df <- as.data.frame(MEM)
UK_df <- as.data.frame(UK)
UK_separated_df <- as.data.frame(UK_separated)
OK_df <- as.data.frame(OK)
colnames(linear_df)
colnames(linear_separated_df)
colnames(MEM_df)
colnames(UK_df)
colnames(UK_separated_df)
colnames(OK_df)
#merge local dataframes to one dataframe, containing all predictions
merge_local = list(linear_df, linear_separated_df, MEM_df, UK_df, UK_separated_df, OK_df)
merge_local <- merge_local %>% reduce(full_join, by= 'key')
merge_local
#rename
merge_local <- merge_local %>% rename("nightlight_450" = "nightlight_450.x",
"nightlight_4950" = "nightlight_4950.x",
"population_1000" = "population_1000.x",
"population_3000" = "population_3000.x"
,"road_class_1_5000" = "road_class_1_5000.x",
"road_class_2_100" = "road_class_2_100.x",
"road_class_2_1000" = "road_class_2_1000.x",
"road_class_1_100" = "road_class_1_100.x" ,
"road_class_2_5000" = "road_class_2_5000.x",
"road_class_3_100" = "road_class_3_100.x",
"road_class_3_300" = "road_class_3_300.x",
"trafBuf50" = "trafBuf50.x")
#filter to only relevant data
local <- merge_local[,c("nightlight_450" ,"nightlight_4950" ,"population_1000","population_3000" ,"road_class_1_5000","road_class_2_100" ,
"road_class_2_1000","road_class_1_100" ,"road_class_2_5000","road_class_3_100","road_class_3_300" ,"trafBuf50" ,"spachar", "key","predNO2_Lin",
"predNO2_LinSep" , "predNO2_MEM" , "predNO2_UK" , "predNO2_UKSep", 'predicted_OK' )]
local
local_sf <- merge(geo, local, by="key")
local_df <- as.data.frame(local)
library("writexl")
#to excel
write_xlsx(local_df, "C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/AllModels/Local_df.xlsx")
#OG_cen <- gCentroid(OverlayGrid,byid=TRUE)
local_cen <- st_centroid(local_sf,byid=TRUE)
#NO2tif
NO2tif <- ('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/no2_Amsterdam/NO2.tif')
NO2tif=raster(NO2tif)
#spatially join
local_and_no2tif = raster::extract(NO2tif, local_cen, sp=T) #sp = T: keep all data
#to dataframe
local_and_no2tif_df <- as.data.frame(local_and_no2tif)
#to grid
local_and_no2tif_grid <- merge(geo, local_and_no2tif_df, by="key")
View(local_and_no2tif_grid)
local_and_no2tif_grid = subset(local_and_no2tif_grid, select = -c(coords.x1,coords.x2) )
## == export option == ##
sf::st_write(local_and_no2tif_grid, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/AllModels/local_and_no2tif_grid.gpkg", driver = "GPKG")
global_sf <- st_as_sf(global)
all_models <- st_join(local_and_no2tif_grid, global_sf, largest = T, left = T)
## == export option == ##
sf::st_write(all_models, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/AllModels/all_models.gpkg", driver = "GPKG")
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
library(rgdal)
library(tmap)    # for static and interactive maps
library(leaflet) # for interactive maps
library(ggplot2) # tidyverse data visualization package
library("ggplot2")
library("GGally")
grid100 = readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/AllModels/all_models.gpkg')
#to datadrame
grid100_df <- as.data.frame(grid100)
# Add fill layer to nz shape
grid100 <- st_as_sf(grid100)
colnames(grid100_df)
View(grid100_df)
grid100_df <- grid100_df %>% rename("Li"  ="predNO2_Lin",
"LiSpa"= "predNO2_LinSep",
"MEM" = "predNO2_MEM",
"Uk" = "predNO2_UK",
"UkSpa" = "predNO2_UKSep",
"Ok" = "predicted_OK",
"RF" =  "predicted_NO2_RF",
"Las" = "predicted_NO2_LASSO",
"Rid" = "predicted_NO2_RIDGE",
"Lgb" = "predicted_NO2_LightGBM",
"Xgb" = "predicted_NO2_XGBoost"
)
colnames(grid100_df)
grid100_df_models <- grid100_df[,c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")]
local <- grid100_df[,c("Li","LiSpa","MEM","Uk","UkSpa","Ok")]
#export local models to csv
write.csv(local, 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/LocalModelData/localmodel_predictions.csv')
#grid100_df_models <- grid100_df[,c("predNO2_Lin","predNO2_LinSep","predNO2_MEM","predNO2_UK","predNO2_UKSep",
# "p_NO2_RF","p_NO2_LA", "p_NO2_RI", "p_NO2_LG", "p_NO2_X")]
#examine statistics per model
summary(grid100_df_models)
grid100_df_noNAs = na.omit(grid100_df_models)
# # use jpg() instead of svg(), if you want PDF output
#jpeg(file = "C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForPredicting/LocalModels - Predicting/MAPS FINAL SCRIPTS - LOCAL/allplot-includingNO2tif.jpeg",width=600, height=350)
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title=""))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
ggsave("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif.jpeg", pm, width = 6, height = 6)
dev.off()
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title=""))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
# # use jpg() instead of svg(), if you want PDF output
#jpeg(file = "C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForPredicting/LocalModels - Predicting/MAPS FINAL SCRIPTS - LOCAL/allplot-includingNO2tif.jpeg",width=600, height=350)
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title="test"))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
#examine statistics per model
summary(grid100_df_models)
#examine statistics per model
summary(grid100_df_models)
grid100_df_noNAs = na.omit(grid100_df_models)
# # use jpg() instead of svg(), if you want PDF output
#jpeg(file = "C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForPredicting/LocalModels - Predicting/MAPS FINAL SCRIPTS - LOCAL/allplot-includingNO2tif.jpeg",width=600, height=350)
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title=""))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
ggsave("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif.jpeg", pm, width = 6, height = 6)
dev.off()
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
library(rgdal)
library(tmap)    # for static and interactive maps
library(leaflet) # for interactive maps
library(ggplot2) # tidyverse data visualization package
library("ggplot2")
library("GGally")
# # use jpg() instead of svg(), if you want PDF output
#jpeg(file = "C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForPredicting/LocalModels - Predicting/MAPS FINAL SCRIPTS - LOCAL/allplot-includingNO2tif.jpeg",width=600, height=350)
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title=""))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
# # use jpg() instead of svg(), if you want PDF output
jpeg(file = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif.jpeg",width=600, height=350)
# # use jpg() instead of svg(), if you want PDF output
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
# # use jpg() instead of svg(), if you want PDF output
pm <- ggpairs(grid100_df_noNAs[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = GGally::wrap(ggally_cor))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
ggsave("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif.jpeg", pm, width = 6, height = 6)
#relevant models
vars = c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok", "no2")
#remove NA values
grid100_df_noNAs = na.omit(grid100_df)
#create empty list where processed data will be stored to.
processed_data <- list()
for(var in vars){
#apply filtering
between0_85 <- grid100_df_noNAs[grid100_df_noNAs[var] < 85 & grid100_df_noNAs[var] > 0, ]
#keep track of progress in for loop via printing
print(var)
#give every processed dataset a unique name that hints to the model used in the fold.
assign(paste0("between0_85", var, sep=""), between0_85[,c(var, "key")])
#examine dimensions
dim(paste0("between0_85", var, sep=""))
#append processed data to list that is defined outside for loop.
processed_data <- c(processed_data, paste0("between0_85", var, sep=""))
}
#examine
processed_data
between0_85_allmodels <- Reduce(function(x,y) merge(x, y, by = "key", all.x = TRUE, all.y = TRUE),
list(between0_85RF, between0_85Lgb,between0_85Xgb,between0_85Las,between0_85Rid,
between0_85Li, between0_85LiSpa, between0_85MEM, between0_85Uk, between0_85UkSpa, between0_85Ok, between0_85no2))
between0_85_allmodels
pm <- ggpairs(between0_85_allmodels[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = wrap(ggally_cor, title=""))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
ggsave("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif-between0_85.jpeg", pm, width = 6, height = 6)
between0_85_allmodels <- Reduce(function(x,y) merge(x, y, by = "key", all.x = TRUE, all.y = TRUE),
list(between0_85RF, between0_85Lgb,between0_85Xgb,between0_85Las,between0_85Rid,
between0_85Li, between0_85LiSpa, between0_85MEM, between0_85Uk, between0_85UkSpa, between0_85Ok, between0_85no2))
between0_85_allmodels
pm <- ggpairs(between0_85_allmodels[, c("RF","Lgb","Xgb","Las","Rid","Li","LiSpa","MEM","Uk","UkSpa","Ok","no2")],
upper = list(continuous = GGally::wrap(ggally_cor))) +
theme(axis.text.x = element_text(angle =90, hjust = 1))
ggsave("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/allplot-includingNO2tif-between0_85.jpeg", pm, width = 6, height = 6)
dev.off()
colnames(grid100)
## == maps == ##
#create list with variables to visualize
vars = c("predNO2_Lin","predNO2_LinSep","predNO2_MEM","predNO2_UK","predNO2_UKSep","predicted_OK",
"predicted_NO2_RF","predicted_NO2_LASSO", "predicted_NO2_RIDGE","predicted_NO2_LightGBM", "predicted_NO2_XGBoost")
length(vars)
breaks = c(-100, 0, 15, 20, 25, 30, 35, 40, 45, 50, 100, 1000)
#manually define color palette
palette <- c("grey", "palegreen4", "palegreen3","palegreen","greenyellow",  "yellow", "gold", "darkorange", "red", "darkred", "grey")
# loop through the shapefiles and create a map for each
for (i in 1:length(vars)) {
vars[i]
map <- tm_shape(grid100) + tm_fill(col = vars[i], breaks=breaks, palette=palette, legend.show = FALSE)
model = vars[i]
tmap_save(map, width = 1000, height = 1000, units="px", filename = paste("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/",model,".jpg", sep=""))
}
#legend visualization
legende <- tm_shape(grid100) + tm_fill(col = "predNO2_Lin", title = "                        Predicted NO2", breaks=breaks, palette=palette, legend.is.portrait = FALSE) + tm_layout(legend.only = T, fontfamily = "serif")
tmap_save(legende, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/Legende.jpg")
## == local predictors == ##
predictors = c("nightlight_450",    "nightlight_4950", "population_1000","population_3000","road_class_1_5000",
"road_class_2_100","road_class_2_1000","road_class_1_100","road_class_2_5000" ,"road_class_3_100",  "road_class_3_300"
,"trafBuf50")
# loop through the shapefiles and create a map for each
for (i in 1:length(predictors)) {
predictors[i]
map <- tm_shape(grid100) + tm_fill(col = predictors[i], legend.show = FALSE)
hi = predictors[i]
tmap_save(map, width = 1000, height = 1000, units="px", filename = paste("C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/local_predictors",hi,".jpg", sep=""))
}
summary(grid100$road_class_2_5000)
breaks_rcl2_5000 = c(0, 10000,20000, 30000, 40000,50000, 60000, 70000, 80000)
palette_rcl2_5000 <- c("palegreen4", "palegreen3","palegreen","greenyellow",  "yellow",  "darkorange", "red", "darkred")
rcl2_5000 = tm_shape(grid100) + tm_fill(col = "road_class_2_5000", breaks=breaks_rcl2_5000, palette=palette_rcl2_5000, legend.show = FALSE)
legende_rcl2_5000 <- tm_shape(grid100) + tm_fill(col = "road_class_2_5000", title = "                        road_class_2_5000", breaks=breaks_rcl2_5000, palette=paleta_rcl2_5000, legend.is.portrait = FALSE) + tm_layout(legend.only = T, fontfamily = "serif")
tmap_save(rcl2_5000, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/rcl2_5000.jpg")
tmap_save(legende_rcl2_5000, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/Legende_rcl2_5000.jpg")
summary(grid100$road_class_2_5000)
breaks_rcl2_5000 = c(0, 10000,20000, 30000, 40000,50000, 60000, 70000, 80000)
palette_rcl2_5000 <- c("palegreen4", "palegreen3","palegreen","greenyellow",  "yellow",  "darkorange", "red", "darkred")
rcl2_5000 = tm_shape(grid100) + tm_fill(col = "road_class_2_5000", breaks=breaks_rcl2_5000, palette=palette_rcl2_5000, legend.show = FALSE)
legende_rcl2_5000 <- tm_shape(grid100) + tm_fill(col = "road_class_2_5000", title = "                        road_class_2_5000", breaks=breaks_rcl2_5000, palette=palette_rcl2_5000, legend.is.portrait = FALSE) + tm_layout(legend.only = T, fontfamily = "serif")
tmap_save(rcl2_5000, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/rcl2_5000.jpg")
tmap_save(legende_rcl2_5000, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/Legende_rcl2_5000.jpg")
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
library(rgdal)
library(tmap)    # for static and interactive maps
library(leaflet) # for interactive maps
library(ggplot2) # tidyverse data visualization package
library("ggplot2")
library("GGally")
#import dataset
grid100 = readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/TooBigData/AllModels/all_models.gpkg')
#define color palette
palette = c("red", "yellow", "green")
#visualize using tmap
map <- tm_shape(grid100) +
tm_polygons("spachar",
palette = palette ,
border.lwd = NA,
legend.show = FALSE,
borders = NULL
)
#save figure
tmap_save(map, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/spachar.jpg")
#map figure apart as this figure is applicable to multiple figures
legende_spachar <- tm_shape(grid100) + tm_fill(col = "spachar", title = "                        Spatial group",  palette=palette, legend.is.portrait = FALSE) + tm_layout(legend.only = T, fontfamily = "serif")
tmap_save(legende_spachar, width = 1000, height = 1000, units="px", filename = "C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/output07/Legende_spachar.jpg")
#visualize using tmap
map <- tm_shape(grid100) +
tm_polygons("spachar",
palette = palette ,
border.lwd = NA,
legend.show = FALSE,
borders = NULL
)
