## == merge all data frames together and assign to measurement stations == ##
#make dataframe spatial
measurement_stations <- st_as_sf(measurement_stations)
measurement_stations <- st_transform(measurement_stations, crs=3035)
#join datasets in list 'merge_list' with each other, based on common M_id
bldden_per_buf <- merge_list %>% reduce(full_join, by='M_id')
#assign to measurement stations, again via common M_id
ms_bldden_per_buf <- left_join(measurement_stations, bldden_per_buf, by = "M_id")
#deselect irrelevant columns
ms_bldden_per_buf <- ms_bldden_per_buf %>% dplyr::select(M_id,  BldDen100, BldDen500, BldDen1000)
#export option
sf::st_write(ms_bldden_per_buf, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/processed", layer='BldDen_ms_StudyArea_Global', driver = "ESRI Shapefile")
require(rgdal)
library(raster)
require(sf)
library(ggplot2)
library(raster)
library(rgeos)
library(tidyverse)
library(sp) #spatial operations
library(leaflet) #mapping in OSM
library(terra) #rasterize
library(stars) #necessary for st_rasterize
## == import building density dataset == ##
#import shapefile of buildingsNL
buildings_3035 <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/polygonbuilding_studyArea.shp')
## == IMPORT NO2 MEASUREMENT STATIONS == ##
NO2_stations <- read.csv(file = 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/InitialGlobalDataset.csv', sep= ";")
#create spatial dataframe from no2 measurement stations dataset
NO2_stations_sf <- st_as_sf(NO2_stations, coords = c("Longitude", "Latitude"))
#assign ooordinate reference system (crs)
st_crs(NO2_stations_sf) <- "+proj=longlat +datum=WGS84 +no_defs +type=crs"
NO2_stations_sf$M_id <- seq(1, 482) #assign unique identifier which will be used for coupling data later in the process
NO2_stations_sf<- NO2_stations_sf%>% dplyr::select(FID,geometry,M_id) #filter columns
## == CREATE BUFFERS AROUND NO2 MEASUREMENT STATIONS == ##
##  First project data into a planar coordinate system
utmStr <- "+proj=utm +zone=%d +datum=NAD83 +units=m +no_defs +ellps=GRS80"
NO2_stations_utm <- st_transform(NO2_stations_sf, crs=3035)
#create different buffers
#initialize buffer parameters
bufs = list(100, 500, 1000)
#create for loop, thereby creating a different buffer per iteration.
buffer_vars = list()
#loop
for(i in bufs){
buf_i <- st_buffer(NO2_stations_utm, i)
assign(paste("buf", i, "m", sep = ""), buf_i)
#assign coordinate sustem
buf_i <- st_as_sf(buf_i)
buf_i$area <- st_area(buf_i)
#store variable in loop
buffer_vars[[paste("buf", i, "m", sep = "")]] <- buf_i
#export option
layer <- paste("buf", i, "m", sep = "")
print(layer)
#sf::st_write(buf_i, dsn='C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity',layer=layer, driver = "ESRI Shapefile")
}
#examine list where variables of previous loop were stored to.
summary(buffer_vars)
#transform crs of building dataset to that of buffers to perform spatial calculations
buildings_3035_sf <-st_as_sf(buildings_3035)
#initialize parameters used in for loop
j = 1
i = 1
merge_list = list()
bldden_ms_list = list()
measurement_stations <- as.data.frame(NO2_stations_utm)
#while loop consists of several spatial operations:
#'clip' for just selecting buildings in buffers
#'intersect' for creating ID for features in corresponding buffer
#'dissolve' to merge features into one, based on common ID (M_id)
#'merge' for calculating building density per buffer
while(j <= length(buffer_vars)){
#set to same crs to perform spatial operations
buffer_vars[[j]] <- st_transform(buffer_vars[[j]], crs=st_crs(buildings_3035_sf))
#clip - building dataset will be assigned to buffers
clip <- buildings_3035_sf[buffer_vars[[j]],]
layer_clip  <- paste0('clip', bufs[[i]], '.shp')
print(layer_clip)
#make clip spatial to export as shapefile
clip <- st_as_sf(clip)
#export option
sf::st_write(clip, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_clip, driver = "ESRI Shapefile")
## == SELECT ROADS WITHIN BUFFER X == ##
intersect_j <- st_intersection(clip, buffer_vars[[j]],  sp = TRUE)
#compute area (m2) for each polygon in dataset
intersect_j$area <- st_area(intersect_j)
layer_intersect  <- paste0('intersect', bufs[[i]], '.shp')
print(layer_intersect)
sf::st_write(intersect_j, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_intersect, driver = "ESRI Shapefile")
#dissolve by common ID - polygons with similar buffer ID will be merged
#the area of these polygons will be aggregated via "SUM"
dissolve <- intersect_j %>% group_by(M_id) %>% summarize(BuiltArea = sum(area))
layer_dissolve  <- paste0('dissolve', bufs[[i]], '.shp')
#export option
sf::st_write(dissolve, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_dissolve, driver = "ESRI Shapefile")
#merge datasets via left_join
#make normal dataframe to perform left_join
bufdata <- as.data.frame(buffer_vars[[j]])
#assign info based on common M_id
merge = left_join(bufdata, dissolve, by = "M_id")
#create new column "building_density" dividing building surface per buffer by
#total buffer surface
merge[[paste("BldDen", bufs[[i]], sep="")]] <- merge$BuiltArea/merge$area
#drop irrelevant columns
merge <- subset(merge, select = -c(FID, geometry.y))
#replace NA by 0
merge[is.na(merge)] <- 0
#store variable in loop
merge_list[[paste0('merge', bufs[[i]])]] <- merge
#assign to variable which can be used as input argument for data export
layer_mer  <- paste0('merge', bufs[[i]], '.shp')
#export option
sf::st_write(merge, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_mer, driver = "ESRI Shapefile")
#next buffer dataset
j = j+1
i = i+1}
## == merge all data frames together and assign to measurement stations == ##
#make dataframe spatial
measurement_stations <- st_as_sf(measurement_stations)
measurement_stations <- st_transform(measurement_stations, crs=3035)
#join datasets in list 'merge_list' with each other, based on common M_id
bldden_per_buf <- merge_list %>% reduce(full_join, by='M_id')
#assign to measurement stations, again via common M_id
ms_bldden_per_buf <- left_join(measurement_stations, bldden_per_buf, by = "M_id")
#deselect irrelevant columns
ms_bldden_per_buf <- ms_bldden_per_buf %>% dplyr::select(M_id,  BldDen100, BldDen500, BldDen1000)
#export option
sf::st_write(ms_bldden_per_buf, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/processed", layer='BldDen_ms_StudyArea_Global', driver = "ESRI Shapefile")
require(rgdal)
library(raster)
require(sf)
library(ggplot2)
library(raster)
library(rgeos)
library(tidyverse)
library(sp) #spatial operations
library(leaflet) #mapping in OSM
library(terra) #rasterize
library(stars) #necessary for st_rasterize
## == import building density dataset == ##
#import shapefile of buildingsNL
buildings_3035 <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/polygonbuilding_studyArea.shp')
## == IMPORT NO2 MEASUREMENT STATIONS == ##
NO2_stations <- read.csv(file = 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/InitialGlobalDataset.csv', sep= ";")
#create spatial dataframe from no2 measurement stations dataset
NO2_stations_sf <- st_as_sf(NO2_stations, coords = c("Longitude", "Latitude"))
#assign ooordinate reference system (crs)
st_crs(NO2_stations_sf) <- "+proj=longlat +datum=WGS84 +no_defs +type=crs"
NO2_stations_sf$M_id <- seq(1, 482) #assign unique identifier which will be used for coupling data later in the process
NO2_stations_sf<- NO2_stations_sf%>% dplyr::select(FID,geometry,M_id) #filter columns
## == CREATE BUFFERS AROUND NO2 MEASUREMENT STATIONS == ##
##  First project data into a planar coordinate system
utmStr <- "+proj=utm +zone=%d +datum=NAD83 +units=m +no_defs +ellps=GRS80"
NO2_stations_utm <- st_transform(NO2_stations_sf, crs=3035)
#create different buffers
#initialize buffer parameters
bufs = list(100, 500, 1000)
#create for loop, thereby creating a different buffer per iteration.
buffer_vars = list()
#loop
for(i in bufs){
buf_i <- st_buffer(NO2_stations_utm, i)
assign(paste("buf", i, "m", sep = ""), buf_i)
#assign coordinate sustem
buf_i <- st_as_sf(buf_i)
buf_i$area <- st_area(buf_i)
#store variable in loop
buffer_vars[[paste("buf", i, "m", sep = "")]] <- buf_i
#export option
layer <- paste("buf", i, "m", sep = "")
print(layer)
#sf::st_write(buf_i, dsn='C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity',layer=layer, driver = "ESRI Shapefile")
}
#examine list where variables of previous loop were stored to.
summary(buffer_vars)
#transform crs of building dataset to that of buffers to perform spatial calculations
buildings_3035_sf <-st_as_sf(buildings_3035)
#initialize parameters used in for loop
j = 1
i = 1
merge_list = list()
bldden_ms_list = list()
measurement_stations <- as.data.frame(NO2_stations_utm)
#while loop consists of several spatial operations:
#'clip' for just selecting buildings in buffers
#'intersect' for creating ID for features in corresponding buffer
#'dissolve' to merge features into one, based on common ID (M_id)
#'merge' for calculating building density per buffer
while(j <= length(buffer_vars)){
#set to same crs to perform spatial operations
buffer_vars[[j]] <- st_transform(buffer_vars[[j]], crs=st_crs(buildings_3035_sf))
#clip - building dataset will be assigned to buffers
clip <- buildings_3035_sf[buffer_vars[[j]],]
layer_clip  <- paste0('clip', bufs[[i]], '.shp')
print(layer_clip)
#make clip spatial to export as shapefile
clip <- st_as_sf(clip)
#export option
#sf::st_write(clip, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_clip, driver = "ESRI Shapefile")
## == SELECT ROADS WITHIN BUFFER X == ##
intersect_j <- st_intersection(clip, buffer_vars[[j]],  sp = TRUE)
#compute area (m2) for each polygon in dataset
intersect_j$area <- st_area(intersect_j)
layer_intersect  <- paste0('intersect', bufs[[i]], '.shp')
print(layer_intersect)
#sf::st_write(intersect_j, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_intersect, driver = "ESRI Shapefile")
#dissolve by common ID - polygons with similar buffer ID will be merged
#the area of these polygons will be aggregated via "SUM"
dissolve <- intersect_j %>% group_by(M_id) %>% summarize(BuiltArea = sum(area))
layer_dissolve  <- paste0('dissolve', bufs[[i]], '.shp')
#export option
#sf::st_write(dissolve, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_dissolve, driver = "ESRI Shapefile")
#merge datasets via left_join
#make normal dataframe to perform left_join
bufdata <- as.data.frame(buffer_vars[[j]])
#assign info based on common M_id
merge = left_join(bufdata, dissolve, by = "M_id")
#create new column "building_density" dividing building surface per buffer by
#total buffer surface
merge[[paste("BldDen", bufs[[i]], sep="")]] <- merge$BuiltArea/merge$area
#drop irrelevant columns
merge <- subset(merge, select = -c(FID, geometry.y))
#replace NA by 0
merge[is.na(merge)] <- 0
#store variable in loop
merge_list[[paste0('merge', bufs[[i]])]] <- merge
#assign to variable which can be used as input argument for data export
layer_mer  <- paste0('merge', bufs[[i]], '.shp')
#export option
#sf::st_write(merge, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/testing_script_outputs/BuildingDensity", layer=layer_mer, driver = "ESRI Shapefile")
#next buffer dataset
j = j+1
i = i+1}
## == merge all data frames together and assign to measurement stations == ##
#make dataframe spatial
measurement_stations <- st_as_sf(measurement_stations)
measurement_stations <- st_transform(measurement_stations, crs=3035)
#join datasets in list 'merge_list' with each other, based on common M_id
bldden_per_buf <- merge_list %>% reduce(full_join, by='M_id')
#assign to measurement stations, again via common M_id
ms_bldden_per_buf <- left_join(measurement_stations, bldden_per_buf, by = "M_id")
#deselect irrelevant columns
ms_bldden_per_buf <- ms_bldden_per_buf %>% dplyr::select(M_id,  BldDen100, BldDen500, BldDen1000)
#export option
sf::st_write(ms_bldden_per_buf, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/processed", layer='BldDen_ms_StudyArea_Global', driver = "ESRI Shapefile")
#necessary libraries
library(sf)
library(sfnetworks)
library(tidygraph)
library(tmap)
library(nngeo)
library(osmdata)
library(dplyr)
library(lwgeom)
library(raster)
library(rgdal)
library(utils)
library(ggplot2)
library(rgeos)
library(tidyverse)
library(leaflet) #mapping in OSM
library(bnspatial)
library(gstat)
library(geosphere) #geosphere::dist2Line
library(stars) #for st_rasterize
library(base) #sprintf
library(sfheaders) #converting to multistring
## == INITIAL DATASET == ## - global dataset
#import initial dataset - csv (no2 measurement station data)
ms_stations <- read.csv(file = 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/InitialGlobalDataset.csv', sep= ";")
#define column with unique identifier
ms_stations$M_id <- seq(1, nrow(ms_stations))
## == adding predictors to global dataset == ##
## == PRECIPITATION == ##
#import precipitation data
#first import all files in a single folder as a list
#define current working directory
setwd("C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/Precipitation/TIFS")  #TIFS are results of script "AssignPrecipitationToMSs.R"
rastlist_precipitation <- list.files(getwd(), pattern='.tif$', all.files=TRUE, full.names=FALSE)
for(i in rastlist_precipitation) { assign(unlist(strsplit(i, "[.]"))[1], raster(i)) }
#assign precipitation data
#create lists that will be used in while loop
tifs <- list(jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec)
tifnames <- list('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec')
# make the SpatialPointsDataFrame object
coords <- ms_stations[, c("Longitude", "Latitude")]
crs <- CRS("+proj=longlat +datum=WGS84")
#create spatial dataframe where precipitation values can be extracted to
spdf_ms_stations <- SpatialPointsDataFrame(coords      = coords,
data        = ms_stations,
proj4string = crs)
#for extraction, a sf dataframe is necessary
spdf_ms_stations <- st_as_sf(spdf_ms_stations)
spdf_ms_stations <- st_transform(spdf_ms_stations, crs = st_crs(tifs[[1]]))
spdf_nodata <- spdf_ms_stations[,("M_id")] #use only column containing unique identifier
#create list where variables can be stored to during iterations
ms_precmonths = list()
#Begin with first element of lists
i = 1
j = 1
#While loop
while(i <= length(tifs))
{ ms_prec <- raster::extract(tifs[[i]], spdf_nodata, sp=TRUE)
#store variable in loop
ms_prec <- as.data.frame(ms_prec)
ms_precmonths[[paste0('prec', tifnames[[j]])]] <- ms_prec
i = i+1
j = j+1
}
#examine
summary(ms_precmonths)
#merge all data frames together
prec_per_month <- ms_precmonths %>% reduce(full_join, by='M_id')
# couple to initial dataset
prec <- merge(spdf_ms_stations,prec_per_month,  by='M_id')
colnames(prec)
#remove unnecessary columns
prec <- prec %>% dplyr::select(-contains("coords"))
#Export option
#sf::st_write(prec_per_month, dsn="C:/Users/foeke/OneDrive/Documenten/ArcGIS/Projects/MyProject22-precipitation", layer='prec_per_month', driver = "ESRI Shapefile")
## == BUILDING DENSITY == ##
#import building density data
buildingdensity_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/processed/BldDen_ms_StudyArea_Global.shp')
#make spatial
buildingdensity_ms_sf <- st_as_sf(buildingdensity_ms)
#to perform spatial join, crs's of input data need to be equal
buildingdensity_ms_sf <- st_transform(buildingdensity_ms_sf, crs=st_crs(prec))
#spatial join
ms_prec_bd <- st_join(prec, buildingdensity_ms_sf, st_nearest_feature)
#clean data
#get rid off NA values
ms_prec_bd <- tidyr::replace_na(ms_prec_bd, list(BldDen100=0, BldDen500=0, BldDen1000=0))
#drop irrelevant columns
ms_prec_bd <- subset(ms_prec_bd, select = -c(M_id.y) )
#Export option
#sf::st_write(ms_prec_bd, dsn="C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForModelling", layer='ms_prec_bd', driver = "ESRI Shapefile")
## == NDVI == ##
#import NDVI data
NDVI_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/NDVI/processed/ms_NDVI_global.shp') #via AssignNDVIToNO2MSs.R
#make spatial
NDVI_ms <- st_as_sf(NDVI_ms)
NDVI_ms <- st_transform(NDVI_ms, crs=st_crs(ms_prec_bd))
#spatial join
ms_prec_bd_ndvi <- st_join(ms_prec_bd, NDVI_ms, st_nearest_feature)
print(ms_prec_bd_ndvi)
#clean data
#drop irrelevant columns
ms_prec_bd_ndvi <- subset(ms_prec_bd_ndvi, select = -c(coords_x1, coords_x2, FID.y) )
#Examine
#view(ms_prec_bd_ndvi)
#export option
# #shapefile
# sf::st_write(ms_prec_bd_ndvi, dsn="C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForModelling", layer='ms_prec_bd_ndvi', driver = "ESRI Shapefile")
## == TRAFFIC VOLUME == ##
#import traffic volume data
trafficvolume_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/Traffic/processed/traffic_NO2_Global.shp') #via "Assigning TrafficVolume to NO2MSs.R"
#make spatial
trafficvolume_ms <- st_as_sf(trafficvolume_ms)
trafficvolume_ms <- st_transform(trafficvolume_ms, crs=st_crs(ms_prec_bd_ndvi))
#spatial join
ms_prec_bd_ndvi_traf <- st_join(ms_prec_bd_ndvi, trafficvolume_ms, st_nearest_feature)
#clean data
#drop irrelevant columns
ms_prec_bd_ndvi_traf <- subset(ms_prec_bd_ndvi_traf, select = -c(M_id.x, M_id) )
#rename
ms_prec_bd_ndvi_traf <- ms_prec_bd_ndvi_traf %>% rename(FID = FID.x)
#examine
view(ms_prec_bd_ndvi_traf)
colnames(ms_prec_bd_ndvi_traf)
ms_prec_bd_ndvi_traf <- replace_na(ms_prec_bd_ndvi_traf, list(trafBuf25=0, trafBuf50=0, trafBuf100=0, trafBuf400=0, trafBuf800=0))
#export options
#shapefile
sf::st_write(ms_prec_bd_ndvi_traf, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData", layer='ModellingDataset-Global', driver = "ESRI Shapefile")
ms_prec_bd_ndvi_traf <- as.data.frame(ms_prec_bd_ndvi_traf)
ms_prec_bd_ndvi_traf <- dplyr::select(ms_prec_bd_ndvi_traf, -c(geometry)) #remove geometry column
ms_prec_bd_ndvi_traf
#csv
write.csv(ms_prec_bd_ndvi_traf, 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/ModellingDataset-Global.csv',col.names = TRUE)
#necessary libraries
library(sf)
library(sfnetworks)
library(tidygraph)
library(tmap)
library(nngeo)
library(osmdata)
library(dplyr)
library(lwgeom)
library(raster)
library(rgdal)
library(utils)
library(ggplot2)
library(rgeos)
library(tidyverse)
library(leaflet) #mapping in OSM
library(bnspatial)
library(gstat)
library(geosphere) #geosphere::dist2Line
library(stars) #for st_rasterize
library(base) #sprintf
library(sfheaders) #converting to multistring
## == INITIAL DATASET == ## - global dataset
#import initial dataset - csv (no2 measurement station data)
ms_stations <- read.csv(file = 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/InitialGlobalDataset.csv', sep= ";")
#define column with unique identifier
ms_stations$M_id <- seq(1, nrow(ms_stations))
## == adding predictors to global dataset == ##
## == PRECIPITATION == ##
#import precipitation data
#first import all files in a single folder as a list
#define current working directory
setwd("C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/Precipitation/TIFS")  #TIFS are results of script "AssignPrecipitationToMSs.R"
rastlist_precipitation <- list.files(getwd(), pattern='.tif$', all.files=TRUE, full.names=FALSE)
for(i in rastlist_precipitation) { assign(unlist(strsplit(i, "[.]"))[1], raster(i)) }
#assign precipitation data
#create lists that will be used in while loop
tifs <- list(jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec)
tifnames <- list('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec')
# make the SpatialPointsDataFrame object
coords <- ms_stations[, c("Longitude", "Latitude")]
crs <- CRS("+proj=longlat +datum=WGS84")
#create spatial dataframe where precipitation values can be extracted to
spdf_ms_stations <- SpatialPointsDataFrame(coords      = coords,
data        = ms_stations,
proj4string = crs)
#for extraction, a sf dataframe is necessary
spdf_ms_stations <- st_as_sf(spdf_ms_stations)
spdf_ms_stations <- st_transform(spdf_ms_stations, crs = st_crs(tifs[[1]]))
spdf_nodata <- spdf_ms_stations[,("M_id")] #use only column containing unique identifier
#create list where variables can be stored to during iterations
ms_precmonths = list()
#Begin with first element of lists
i = 1
j = 1
#While loop
while(i <= length(tifs))
{ ms_prec <- raster::extract(tifs[[i]], spdf_nodata, sp=TRUE)
#store variable in loop
ms_prec <- as.data.frame(ms_prec)
ms_precmonths[[paste0('prec', tifnames[[j]])]] <- ms_prec
i = i+1
j = j+1
}
#examine
summary(ms_precmonths)
#merge all data frames together
prec_per_month <- ms_precmonths %>% reduce(full_join, by='M_id')
# couple to initial dataset
prec <- merge(spdf_ms_stations,prec_per_month,  by='M_id')
colnames(prec)
#remove unnecessary columns
prec <- prec %>% dplyr::select(-contains("coords"))
#Export option
#sf::st_write(prec_per_month, dsn="C:/Users/foeke/OneDrive/Documenten/ArcGIS/Projects/MyProject22-precipitation", layer='prec_per_month', driver = "ESRI Shapefile")
## == BUILDING DENSITY == ##
#import building density data
buildingdensity_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/BuildingDensity/processed/BldDen_ms_StudyArea_Global.shp')
#make spatial
buildingdensity_ms_sf <- st_as_sf(buildingdensity_ms)
#to perform spatial join, crs's of input data need to be equal
buildingdensity_ms_sf <- st_transform(buildingdensity_ms_sf, crs=st_crs(prec))
#spatial join
ms_prec_bd <- st_join(prec, buildingdensity_ms_sf, st_nearest_feature)
#clean data
#get rid off NA values
ms_prec_bd <- tidyr::replace_na(ms_prec_bd, list(BldDen100=0, BldDen500=0, BldDen1000=0))
#drop irrelevant columns
ms_prec_bd <- subset(ms_prec_bd, select = -c(M_id.y) )
#Export option
#sf::st_write(ms_prec_bd, dsn="C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForModelling", layer='ms_prec_bd', driver = "ESRI Shapefile")
## == NDVI == ##
#import NDVI data
NDVI_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/NDVI/processed/ms_NDVI_global.shp') #via AssignNDVIToNO2MSs.R
#make spatial
NDVI_ms <- st_as_sf(NDVI_ms)
NDVI_ms <- st_transform(NDVI_ms, crs=st_crs(ms_prec_bd))
#spatial join
ms_prec_bd_ndvi <- st_join(ms_prec_bd, NDVI_ms, st_nearest_feature)
print(ms_prec_bd_ndvi)
#clean data
#drop irrelevant columns
ms_prec_bd_ndvi <- subset(ms_prec_bd_ndvi, select = -c(coords_x1, coords_x2, FID.y) )
#Examine
#view(ms_prec_bd_ndvi)
#export option
# #shapefile
# sf::st_write(ms_prec_bd_ndvi, dsn="C:/Users/foeke/OneDrive/Documenten/april onwards/2022/Initial dataset/ForModelling", layer='ms_prec_bd_ndvi', driver = "ESRI Shapefile")
## == TRAFFIC VOLUME == ##
#import traffic volume data
trafficvolume_ms <- readOGR('C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/Traffic/processed/traffic_NO2_Global.shp') #via "Assigning TrafficVolume to NO2MSs.R"
#make spatial
trafficvolume_ms <- st_as_sf(trafficvolume_ms)
trafficvolume_ms <- st_transform(trafficvolume_ms, crs=st_crs(ms_prec_bd_ndvi))
#spatial join
ms_prec_bd_ndvi_traf <- st_join(ms_prec_bd_ndvi, trafficvolume_ms, st_nearest_feature)
#clean data
#drop irrelevant columns
ms_prec_bd_ndvi_traf <- subset(ms_prec_bd_ndvi_traf, select = -c(M_id.x, M_id) )
#rename
ms_prec_bd_ndvi_traf <- ms_prec_bd_ndvi_traf %>% rename(FID = FID.x)
#examine
view(ms_prec_bd_ndvi_traf)
colnames(ms_prec_bd_ndvi_traf)
ms_prec_bd_ndvi_traf <- replace_na(ms_prec_bd_ndvi_traf, list(trafBuf25=0, trafBuf50=0, trafBuf100=0, trafBuf400=0, trafBuf800=0))
#export options
#shapefile
sf::st_write(ms_prec_bd_ndvi_traf, dsn="C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData", layer='ModellingDataset-Global', driver = "ESRI Shapefile")
ms_prec_bd_ndvi_traf <- as.data.frame(ms_prec_bd_ndvi_traf)
ms_prec_bd_ndvi_traf <- dplyr::select(ms_prec_bd_ndvi_traf, -c(FID, geometry)) #remove geometry column
ms_prec_bd_ndvi_traf
#csv
write.csv(ms_prec_bd_ndvi_traf, 'C:/Users/foeke/OneDrive/Documenten/submitting paper/All scripts - paper/data/GlobalModelData/ModellingDataset-Global.csv',col.names = TRUE)
